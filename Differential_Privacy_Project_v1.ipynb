{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jgnjb0HRJ69b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, SubsetRandomSampler\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "FQrGH00KJ69m",
    "outputId": "07ea3d8a-fdd0-4573-d8ce-aa4e9bdd13c3"
   },
   "outputs": [],
   "source": [
    "#download the data\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(),download = True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "#mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n5icqaUjJ69v"
   },
   "source": [
    "# Datasets (data + labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "eNC-rhLyJ69y",
    "outputId": "1e7ca008-ee41-4e1f-c966-5a9d8965ca6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "l7YIf6sTJ697",
    "outputId": "17898444-7f9b-4da5-c371-5ae3501ec9f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WzRfxpVGXHGV",
    "outputId": "421067ef-bc4e-4d0d-c608-62a63e66eb02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train.train dataset = 50000 \n",
      "Train.valid dataset= 10000\n"
     ]
    }
   ],
   "source": [
    "#split train dataset into train.train/train.valid\n",
    "\n",
    "train_size = int(5 * len(train_dataset)/6)\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train_ds, valid_ds = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "print(f\"Train.train dataset = {len(train_ds)}\",\n",
    "      f\"\\nTrain.valid dataset= {len(valid_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4dBHVIW1KPo5"
   },
   "outputs": [],
   "source": [
    "#split train.train dataset into 10 teachers train/valid datasets\n",
    "#see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UtL9FNNkl0bE"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Defining the layers, 784, 256, 10 units each\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = F.softmax(x, dim=1)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        return x\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "TPk_g7N8jvxr",
    "outputId": "11a8a999-ce6c-4d45-c1db-d74b7f667b39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WAelf4GTMqv4"
   },
   "outputs": [],
   "source": [
    "#batch_size = 64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train_ds, batch_size=64,shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(dataset=valid_ds, batch_size=64,shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "uofbq0j1KM_S",
    "outputId": "e54065e4-8684-4c47-a10f-31216e2d9816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/12..  Training Loss: -0.798139..  Test Loss: -0.843637..  Test Accuracy: 0.848428\n",
      "Epoch: 2/12..  Training Loss: -0.859304..  Test Loss: -0.898462..  Test Accuracy: 0.907046\n",
      "Epoch: 3/12..  Training Loss: -0.938268..  Test Loss: -0.945936..  Test Accuracy: 0.950537\n",
      "Epoch: 4/12..  Training Loss: -0.954914..  Test Loss: -0.952757..  Test Accuracy: 0.955514\n",
      "Epoch: 5/12..  Training Loss: -0.962358..  Test Loss: -0.958448..  Test Accuracy: 0.960490\n",
      "Epoch: 6/12..  Training Loss: -0.968685..  Test Loss: -0.962063..  Test Accuracy: 0.964271\n",
      "Epoch: 7/12..  Training Loss: -0.972777..  Test Loss: -0.965705..  Test Accuracy: 0.966859\n",
      "Epoch: 8/12..  Training Loss: -0.975624..  Test Loss: -0.965349..  Test Accuracy: 0.966461\n",
      "Epoch: 9/12..  Training Loss: -0.977646..  Test Loss: -0.968256..  Test Accuracy: 0.969347\n",
      "Epoch: 10/12..  Training Loss: -0.979746..  Test Loss: -0.967585..  Test Accuracy: 0.968650\n",
      "Epoch: 11/12..  Training Loss: -0.981338..  Test Loss: -0.969702..  Test Accuracy: 0.971039\n",
      "Epoch: 12/12..  Training Loss: -0.982242..  Test Loss: -0.971626..  Test Accuracy: 0.972830\n"
     ]
    }
   ],
   "source": [
    "#train the model on the whole 'MNIST' to tune hyperparameter\n",
    "\n",
    "device = 'cuda'\n",
    "epochs = 12\n",
    "count = 0\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "  \n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    train_count = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #output = model(images)\n",
    "        output = model.forward(images)\n",
    "        \n",
    "        #print(output.shape, labels.shape)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        #print(train_count)\n",
    "        train_count+=1\n",
    "  \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "            \n",
    "        with torch.no_grad():\n",
    "            #test_count =0\n",
    "            for inputs, labels in testloader:\n",
    "                \n",
    "                inputs = inputs.view(inputs.shape[0], -1)\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                log_ps = model.forward(inputs)\n",
    "                \n",
    "                #print(labels.shape,log_ps.shape)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "                #test_count +=1\n",
    "                \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.6f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.6f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.6f}\".format(accuracy/len(testloader))\n",
    "              )\n",
    "    \n",
    "    #collect train_losses and test_losses for each epoch\n",
    "    #train_losses.append(running_loss/len(trainloader))\n",
    "    #test_losses.append(test_loss/len(testloader))\n",
    "        \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nXCUUEMJ6-s"
   },
   "outputs": [],
   "source": [
    "#++++++++++++TODO\n",
    "  #+++++++++split MNIST train dataset on train.train/train.valid\n",
    "\n",
    "  #+++++++++create 10 teachers' datasets from train.train //train_ds//\n",
    "  #+++++++++split 10 teachers' train.train dataset in train/valid\n",
    "  #output:\n",
    "  #teacher_train_loader = [1 ... 10]\n",
    "  #teacher_valid_loader = [1 ... 10]\n",
    "    \n",
    "#TODO\n",
    "  #train_with_teacher() 10 models on 10 splitted trainsets\n",
    "   \n",
    "#TODO   \n",
    "  #model.forward(train.valid_dataset) //valid_ds//\n",
    "  #return 10 sets of true_labels = []  \n",
    "    \n",
    "#TODO\n",
    "  #dp_labels = true_labels + laplacianM\n",
    "\n",
    "#TODO\n",
    "  #split train.valid_dataset and true_labels on train/valid\n",
    "  #train.valid.train_loader\n",
    "  #train.valid.valid_loader\n",
    "\n",
    "  #train_model(train.valid_dataset + dp_labels)\n",
    "\n",
    "#TODO\n",
    "  #predict(MNIST test_dataset)\n",
    "  #compare predictions accuracy for true labels and dp_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7o96o7TJ6-h"
   },
   "source": [
    "# Let's divide train data into 10 private datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bOwtJGNiJ6-i",
    "outputId": "3b3d2de5-1f60-46af-e984-0c46a34bb8bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_ind = 50000 teacher_subset = 5000\n"
     ]
    }
   ],
   "source": [
    "#num_teachers = int(len(train_dataset)/len(test_dataset)) # we're working with  private datasets\n",
    "num_examples = len(train_ds) # the size of OUR dataset\n",
    "num_labels = 10 # number of lablels for our classifier\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "max_ind= num_examples   #50000\n",
    "num_teachers = 10\n",
    "teacher_subset = int(max_ind/num_teachers)\n",
    "\n",
    "print(f\"max_ind = {max_ind}\",f\"teacher_subset = {teacher_subset}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zO5RsOdIiCT"
   },
   "outputs": [],
   "source": [
    "#print(len(test_dataset))\n",
    "#test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size=1)\n",
    "#test_loader\n",
    "\n",
    "#train_loader10 = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=teacher_subset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5J0G1w6J6-o"
   },
   "outputs": [],
   "source": [
    "def split_train_ds():\n",
    "\n",
    "    max_ind= num_examples  #50000\n",
    "    teacher_len = int(max_ind/num_teachers)\n",
    "\n",
    "    \n",
    "\n",
    "    teacher_train_loader = []\n",
    "    teacher_valid_loader = []\n",
    "\n",
    "    start = 0\n",
    "    stop = teacher_len                          #5000\n",
    "    train_size = int(0.8* teacher_len)          #4000\n",
    "    test_size = teacher_len - train_size        #1000\n",
    "    \n",
    "    print(f\"start = {start}\",f\"train_size = {train_size}\",f\"test_size = {test_size}\")\n",
    "\n",
    "    indicies = torch.randperm(max_ind)\n",
    "\n",
    "    for i in range(num_teachers):\n",
    "        idx =[j for j in range(start,stop)]\n",
    "        idx = indicies[start:stop]\n",
    "        \n",
    "        #split teacher_j dataset into train/validation\n",
    "\n",
    "        \n",
    "        #train_teach_ds, test__teach_ds = torch.utils.data.random_split(train_dataset, [train_size, test_size])\n",
    "        \n",
    "        #split every teacher subset into train/valid\n",
    "        train_t_idx=indicies[start:(start+train_size)]\n",
    "        valid_t_idx = indicies[(start+train_size): stop]\n",
    "\n",
    "        #print(f\"Teacher Train dataset = {start+train_size}\",\n",
    "              #f\"\\nTeacher Valid dataset= {stop}\")\n",
    "    \n",
    "        teacher_train_loader.append(torch.utils.data.DataLoader( train_ds, batch_size=batch_size, sampler = SubsetRandomSampler(train_t_idx)))\n",
    "        teacher_valid_loader.append(torch.utils.data.DataLoader( train_ds, batch_size=batch_size, sampler = SubsetRandomSampler(valid_t_idx)))\n",
    "        \n",
    "        #print(f\"teacher_train_loader = {len(teacher_train_loader[i])}\",f\"teacher_valid_loader = {len(teacher_valid_loader[i])}\")\n",
    "    \n",
    "        start = stop\n",
    "        stop = stop+teacher_len\n",
    "        \n",
    "    return teacher_train_loader, teacher_valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "u8lri8iWJ6-p",
    "outputId": "5095c724-da2d-4a61-aead-d4005b815fd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start = 0 train_size = 4000 test_size = 1000\n",
      "10 10\n"
     ]
    }
   ],
   "source": [
    "teacher_train_loader,teacher_valid_loader = split_train_ds()\n",
    "print(len(teacher_train_loader), len(teacher_valid_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EOVp2h8Yr0Ws"
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SQ1gS9yoJ6-6"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Defining the layers, 128, 64, 10 units each\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "gkfaP_C0J6-1",
    "outputId": "36d4ee88-3fee-4736-b9d8-5dbf1ee1800f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cek7VYhT_4ep"
   },
   "source": [
    "# Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kun97w7Wv6xg"
   },
   "outputs": [],
   "source": [
    "def evaluate_model_t(device,criterion,optimizer,testloader):\n",
    "    \n",
    "    #device = device\n",
    "    test_loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "                \n",
    "         for inputs, labels in testloader[t]:\n",
    "\n",
    "            inputs = inputs.view(inputs.shape[0], -1)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            log_ps = model.forward(inputs)\n",
    "\n",
    "            #print(labels.shape,log_ps.shape)\n",
    "            test_loss += criterion(log_ps, labels)\n",
    "\n",
    "            ps = torch.exp(log_ps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            acc += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            #test_count +=1\n",
    "            \n",
    "    return test_loss, acc       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AwiligkBwDYN"
   },
   "outputs": [],
   "source": [
    "def train_model_t(trainloader,testloader):\n",
    "    \n",
    "    device = 'cuda'\n",
    "    epochs = 5\n",
    "    count = 0\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    #testloader = testloader\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    accuracy =  []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        train_count = 0\n",
    "\n",
    "        for images, labels in trainloader[t]:\n",
    "            # Flatten MNIST images into a 784 long vector\n",
    "            images = images.view(images.shape[0], -1)\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # TODO: Training pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #output = model(images)\n",
    "            output = model.forward(images)\n",
    "\n",
    "            #print(output.shape, labels.shape)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            #print(train_count)\n",
    "            train_count+=1\n",
    "            \n",
    "        else:\n",
    "            #model evaluation\n",
    "            test_loss,acc = evaluate_model_t(device,criterion,optimizer,testloader)\n",
    "\n",
    "            #collect accuracy, train_losses and test_losses for each epoch\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))\n",
    "            accuracy.append(acc/len(testloader))\n",
    "        \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.6f}.. \".format(train_losses[e]),\n",
    "                  \"Test Loss: {:.6f}.. \".format(test_losses[e]),\n",
    "                  \"Test Accuracy: {:.6f}\".format(accuracy[e])\n",
    "                  )\n",
    "            \n",
    "        \n",
    "    return -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYw_HLlvwsEX"
   },
   "outputs": [],
   "source": [
    "for t in range(num_teachers):\n",
    "    print(f\"Teacher {t+1}\")\n",
    "    train_model_t(teacher_train_loader,teacher_valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6XhwueKowr06"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeOlpKPcwrlN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJ2qaE-NJoY4"
   },
   "outputs": [],
   "source": [
    "def evaluate_model_1(device,criterion,optimizer):\n",
    "    \n",
    "    #device = device\n",
    "    test_loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "                \n",
    "         for inputs, labels in testloader:\n",
    "\n",
    "            inputs = inputs.view(inputs.shape[0], -1)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            log_ps = model.forward(inputs)\n",
    "\n",
    "            #print(labels.shape,log_ps.shape)\n",
    "            test_loss += criterion(log_ps, labels)\n",
    "\n",
    "            ps = torch.exp(log_ps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            acc += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            #test_count +=1\n",
    "            \n",
    "    return test_loss, acc       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2Sx4KD-Cgwt"
   },
   "outputs": [],
   "source": [
    "def train_model_1():\n",
    "    \n",
    "    device = 'cuda'\n",
    "    epochs = 5\n",
    "    count = 0\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    accuracy =  []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        train_count = 0\n",
    "\n",
    "        for images, labels in trainloader:\n",
    "            # Flatten MNIST images into a 784 long vector\n",
    "            images = images.view(images.shape[0], -1)\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # TODO: Training pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #output = model(images)\n",
    "            output = model.forward(images)\n",
    "\n",
    "            #print(output.shape, labels.shape)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            #print(train_count)\n",
    "            train_count+=1\n",
    "            \n",
    "        else:\n",
    "            #model evaluation\n",
    "            test_loss,acc = evaluate_model(device,criterion,optimizer)\n",
    "\n",
    "            #collect accuracy, train_losses and test_losses for each epoch\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))\n",
    "            accuracy.append(acc/len(testloader))\n",
    "        \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.6f}.. \".format(train_losses[e]),\n",
    "                  \"Test Loss: {:.6f}.. \".format(test_losses[e]),\n",
    "                  \"Test Accuracy: {:.6f}\".format(accuracy[e])\n",
    "                  )\n",
    "            \n",
    "        \n",
    "    return -1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ur2iZ7UyI9_L",
    "outputId": "b7e09592-5ba8-4e0e-ee88-13ed0f35d35f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5..  Training Loss: -0.971199..  Test Loss: -0.957043..  Test Accuracy: 0.957205\n",
      "Epoch: 2/5..  Training Loss: -0.971614..  Test Loss: -0.954605..  Test Accuracy: 0.955215\n",
      "Epoch: 3/5..  Training Loss: -0.972090..  Test Loss: -0.956682..  Test Accuracy: 0.956509\n",
      "Epoch: 4/5..  Training Loss: -0.969195..  Test Loss: -0.960389..  Test Accuracy: 0.960092\n",
      "Epoch: 5/5..  Training Loss: -0.972667..  Test Loss: -0.967962..  Test Accuracy: 0.968252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQyH0fZsJ6-l"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "j=0\n",
    "\n",
    "for i in range(len(train_targets)):\n",
    "    \n",
    "    images.append(train_data[i])\n",
    "    labels.append(train_targets[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (i+1)%6000==0:\n",
    "        print (\"Teacher \", j)\n",
    "        print(len(images),len(labels))\n",
    "        images.clear()\n",
    "        labels.clear() \n",
    "        j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzV-8-raJ6-j"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "image_folder=[]\n",
    "label_folder=[]\n",
    "j=0\n",
    "\n",
    "for i in range(len(train_targets)):\n",
    "    \n",
    "    images.append(train_data[i])\n",
    "    labels.append(train_targets[i])\n",
    "    \n",
    "    if (i+1)%6000==0:\n",
    "        print (j)\n",
    "        image_folder.append(images) \n",
    "        #label_folder[j] = labels\n",
    "        \n",
    "        #images = []\n",
    "        #labels = []\n",
    "        j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zW4lluvDQ-7-"
   },
   "outputs": [],
   "source": [
    "class Teacher():\n",
    "  \n",
    "  def __init__(self, loader, dest)\n",
    "  \n",
    "    self.image_loader = loader\n",
    "    self.destination = dest\n",
    "    \n",
    "    batch_size = 60\n",
    "    #n_iters = 1000\n",
    "    #epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "    \n",
    "    self.criterion = nn.NLLLoss()\n",
    "    self.optimaizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "    \n",
    "    \n",
    "  def train(self):\n",
    "    \n",
    "    model.to('cuda')\n",
    "\n",
    "\n",
    "    device = 'cuda'\n",
    "    epochs = 5\n",
    "    steps = 0\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    \n",
    "    \n",
    "    for e in range(epochs):\n",
    "      \n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        for inputs, labels in trainloader:\n",
    "        \n",
    "            #model.train()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "            preds = model.forward(inputs)\n",
    "            loss = criterion(preds, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        else:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "        \n",
    "            model.eval()\n",
    "        \n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "              \n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                    log_ps = model.forward(inputs)\n",
    "                    test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                    ps = torch.exp(log_ps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))\n",
    "        \n",
    "        running_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "      \n",
    "      \n",
    "    return accuracy\n",
    "      \n",
    "      \n",
    "  def get_labels():\n",
    "    \n",
    "    return true_labels\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qdX0YXcpoOzp",
    "outputId": "51d9a16a-0451-4a00-f10b-53bd78a4714c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(testloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "print(output.shape,labels.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Differential_Privacy_Project_v1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
